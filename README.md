# HW-2-Cloud-Computing


	For the first part of this assignment, I designed a movie recommendation system using K-Means clustering on my dataset. The data I was working with in the ratings data contained data for user IDs, Movie IDs and ratings from 1-5. The subsequent dataset for movies contained the titles for each movie ID and its affiliated genre. First, I had to initiate a spark session using pySpark. For the data cleaning, my first task was to parse the data. Then, I had to merge the data frames together with a left join and assigned to a variable.  Then, I had to vectorize the word data on the merged data frame to obtain meaningful interpretation on the text categories. I also then dropped irrelevant categories in the data so that I was only left with MovieID, Title, and Genre on my movies data and userID, MovieID, and rating on my ratings data. When building the k-means model, I first had to what the optimal number of clusters was. In this case, k optimal = 6. I could then use this information to build my k-means model on that number of clusters and discover my recommendation system’s accuracy using those clusters. The two systems can be compared using the RMSE from the ALS model and the silhouette score on the k-means model. The model with the highest accuracy is better performing. In this case, the k-means outperformed the ALS by getting an accuracy score of .99 vs .86 for the ALS model. To run this code, it can be tuned to any dataset by being imported using sparks “spark.read” function. From there, the code can be manipulated and ran on any dataset by adjusting the column category names and reapplying the program. The program takes approximately one hour to run the ALS program when fitting the validator to the training set. The rest of the program runs relatively instantaneous, with the exception of running the silhouette plots on k-means.
